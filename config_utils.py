"""
config_utils.py
===============
Utility script ƒë·ªÉ hi·ªÉn th·ªã config training tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu
H·ªó tr·ª£ Swin-Unet training
"""

import os
import sys
from pathlib import Path
from datetime import datetime

try:
    from rich.console import Console
    from rich.table import Table
    from rich.panel import Panel
    from rich.text import Text
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    print("Warning: Rich library not installed. Using basic print.")

# ============================================================================
# CLASS HI·ªÇN TH·ªä CONFIG
# ============================================================================

class ConfigDisplay:
    """Hi·ªÉn th·ªã config training m·ªôt c√°ch ƒë·∫πp v√† r√µ r√†ng"""
    
    def __init__(self, use_rich=True):
        self.use_rich = use_rich and RICH_AVAILABLE
        if self.use_rich:
            self.console = Console()
        else:
            self.console = None
    
    def print_header(self, title):
        """In header"""
        if self.use_rich:
            self.console.print(f"\n[bold cyan]{title}[/bold cyan]")
        else:
            print(f"\n{'='*80}")
            print(f"{title:^80}")
            print(f"{'='*80}")
    
    def print_section(self, section_name, items_dict):
        """In m·ªôt section config"""
        if self.use_rich:
            # S·ª≠ d·ª•ng Rich table
            table = Table(
                title=section_name,
                style="cyan",
                show_header=True,
                header_style="bold magenta"
            )
            table.add_column("Parameter", style="green", width=30)
            table.add_column("Value", style="yellow", width=50)
            
            for key, value in items_dict.items():
                table.add_row(str(key), str(value))
            
            self.console.print(table)
        else:
            # S·ª≠ d·ª•ng print b√¨nh th∆∞·ªùng
            print(f"\n{section_name}")
            print("-" * 80)
            for key, value in items_dict.items():
                print(f"  {key:<28} {value}")
    
    def print_success(self, message):
        """In th√¥ng b√°o th√†nh c√¥ng"""
        if self.use_rich:
            self.console.print(f"[bold green] {message}[/bold green]")
        else:
            print(f" {message}")
    
    def print_warning(self, message):
        """In th√¥ng b√°o c·∫£nh b√°o"""
        if self.use_rich:
            self.console.print(f"[bold yellow]  {message}[/bold yellow]")
        else:
            print(f"  {message}")
    
    def print_error(self, message):
        """In th√¥ng b√°o l·ªói"""
        if self.use_rich:
            self.console.print(f"[bold red] {message}[/bold red]")
        else:
            print(f" {message}")
    
    def print_footer(self, message):
        """In footer"""
        if self.use_rich:
            footer_text = Text(message, style="bold green")
            self.console.print(Panel(footer_text, border_style="green"))
        else:
            print(f"\n{'='*80}")
            print(f"{message:^80}")
            print(f"{'='*80}\n")

# ============================================================================
# H√ÄM KI·ªÇM TRA CONFIG
# ============================================================================

def check_paths(args):
    """Ki·ªÉm tra c√°c ƒë∆∞·ªùng d·∫´n"""
    issues = []
    
    # Ki·ªÉm tra list_dir
    list_dir = args.list_dir
    if not os.path.exists(list_dir):
        issues.append(f"List directory kh√¥ng t·ªìn t·∫°i: {list_dir}")
    else:
        # Ki·ªÉm tra train.txt
        train_txt = os.path.join(list_dir, "train.txt")
        if not os.path.exists(train_txt):
            issues.append(f"train.txt kh√¥ng t·ªìn t·∫°i: {train_txt}")
        else:
            with open(train_txt, 'r') as f:
                train_lines = len(f.readlines())
            if train_lines == 0:
                issues.append("train.txt r·ªóng")
        
        # Ki·ªÉm tra val.txt
        val_txt = os.path.join(list_dir, "val.txt")
        if not os.path.exists(val_txt):
            issues.append(f"val.txt kh√¥ng t·ªìn t·∫°i: {val_txt}")
        else:
            with open(val_txt, 'r') as f:
                val_lines = len(f.readlines())
    
    # Ki·ªÉm tra root_path
    root_path = args.root_path
    if not os.path.exists(root_path):
        issues.append(f"Root path kh√¥ng t·ªìn t·∫°i: {root_path}")
    
    # Ki·ªÉm tra output_dir c√≥ th·ªÉ t·∫°o ƒë∆∞·ª£c kh√¥ng
    output_dir = args.output_dir
    try:
        os.makedirs(output_dir, exist_ok=True)
    except Exception as e:
        issues.append(f"Kh√¥ng th·ªÉ t·∫°o output directory: {str(e)}")
    
    # Ki·ªÉm tra config file
    if args.cfg and not os.path.exists(args.cfg):
        issues.append(f"Config file kh√¥ng t·ªìn t·∫°i: {args.cfg}")
    
    return issues

def check_parameters(args):
    """Ki·ªÉm tra c√°c tham s·ªë training"""
    issues = []
    
    # Ki·ªÉm tra num_classes
    if hasattr(args, 'num_classes'):
        if args.num_classes != 9:
            issues.append(f"num_classes = {args.num_classes}, n√™n l√† 9 cho Synapse")
    
    # Ki·ªÉm tra batch_size
    if hasattr(args, 'batch_size'):
        if args.batch_size < 1 or args.batch_size > 128:
            issues.append(f"batch_size = {args.batch_size} c√≥ th·ªÉ qu√° l·ªõn")
    
    # Ki·ªÉm tra img_size
    if hasattr(args, 'img_size'):
        if args.img_size != 224:
            issues.append(f"img_size = {args.img_size}, khuy·∫øn ngh·ªã 224")
    
    # Ki·ªÉm tra base_lr
    if hasattr(args, 'base_lr'):
        if args.base_lr <= 0 or args.base_lr > 1.0:
            issues.append(f"base_lr = {args.base_lr} kh√¥ng h·ª£p l·ªá")
    
    return issues

# ============================================================================
# H√ÄM HI·ªÇN TH·ªä CONFIG
# ============================================================================

def display_training_config(args, config=None):
    """
    Hi·ªÉn th·ªã to√†n b·ªô config training
    
    Args:
        args: Namespace t·ª´ argparse
        config: Config object t·ª´ get_config() (t√πy ch·ªçn)
    
    Returns:
        bool: True n·∫øu config h·ª£p l·ªá, False n·∫øu c√≥ l·ªói
    """
    
    display = ConfigDisplay(use_rich=RICH_AVAILABLE)
    
    # ========================================================================
    # PH·∫¶N 1: HEADER
    # ========================================================================
    if display.use_rich:
        display.console.clear()
    
    print("\n" + "="*80)
    print("| "*40)
    print("| SWIN-UNET TRAINING CONFIGURATION |")
    print("| "*40)
    print("="*80)
    
    # ========================================================================
    # PH·∫¶N 2: DATASET CONFIGURATION
    # ========================================================================
    dataset_config = {
        "Dataset": args.dataset if hasattr(args, 'dataset') else "N/A",
        "Root Path": args.root_path if hasattr(args, 'root_path') else "N/A",
        "List Directory": args.list_dir if hasattr(args, 'list_dir') else "N/A",
        "Output Directory": args.output_dir if hasattr(args, 'output_dir') else "N/A",
    }
    display.print_section(" DATASET CONFIGURATION", dataset_config)
    
    # ========================================================================
    # PH·∫¶N 3: MODEL CONFIGURATION
    # ========================================================================
    model_config = {
        "Config File": args.cfg if hasattr(args, 'cfg') else "N/A",
        "Image Size": f"{args.img_size}x{args.img_size}" if hasattr(args, 'img_size') else "N/A",
        "Number of Classes": args.num_classes if hasattr(args, 'num_classes') else "N/A",
    }
    display.print_section("üîß MODEL CONFIGURATION", model_config)
    
    # ========================================================================
    # PH·∫¶N 4: TRAINING PARAMETERS
    # ========================================================================
    training_params = {
        "Batch Size": args.batch_size if hasattr(args, 'batch_size') else "N/A",
        "Number of GPUs": args.n_gpu if hasattr(args, 'n_gpu') else "N/A",
        "Max Epochs": args.max_epochs if hasattr(args, 'max_epochs') else "N/A",
        "Base Learning Rate": f"{args.base_lr:.5f}" if hasattr(args, 'base_lr') else "N/A",
        "Weight Decay": "0.0001",
    }
    display.print_section("üìà TRAINING PARAMETERS", training_params)
    
    # ========================================================================
    # PH·∫¶N 5: MISC SETTINGS
    # ========================================================================
    misc_config = {
        "Number of Workers": args.num_workers if hasattr(args, 'num_workers') else "4",
        "Evaluation Interval": args.eval_interval if hasattr(args, 'eval_interval') else "1",
        "Random Seed": args.seed if hasattr(args, 'seed') else "1234",
        "Deterministic": args.deterministic if hasattr(args, 'deterministic') else "1",
    }
    display.print_section("  MISC SETTINGS", misc_config)
    
    # ========================================================================
    # PH·∫¶N 6: KI·ªÇM TRA H·ª¢PL·ªÜ
    # ========================================================================
    print("\n" + "="*80)
    print(" KI·ªÇM TRA C·∫§U H√åNH")
    print("="*80)
    
    # Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n
    path_issues = check_paths(args)
    param_issues = check_parameters(args)
    
    all_issues = path_issues + param_issues
    
    if not all_issues:
        display.print_success("T·∫•t c·∫£ ƒë∆∞·ªùng d·∫´n v√† tham s·ªë ƒë·ªÅu h·ª£p l·ªá!")
        display.print_footer(" S·∫¥N S√ÄNG TRAIN - B·∫Øt ƒë·∫ßu training ngay!")
        return True
    else:
        if path_issues:
            print("\n PATH ISSUES:")
            for issue in path_issues:
                display.print_error(issue)
        
        if param_issues:
            print("\n  PARAMETER WARNINGS:")
            for issue in param_issues:
                display.print_warning(issue)
        
        if any("kh√¥ng t·ªìn t·∫°i" in issue or "l·ªói" in issue.lower() for issue in all_issues):
            print("\n" + "="*80)
            print(" L·ªñI NGHI√äM TR·ªåNG - KH√îNG TH·ªÇ TRAIN")
            print("Vui l√≤ng s·ª≠a c√°c l·ªói tr√™n tr∆∞·ªõc khi training")
            print("="*80 + "\n")
            return False
        else:
            print("\n" + "="*80)
            print("  C√ì C·∫¢NH B√ÅO - H√£y ki·ªÉm tra k·ªπ tr∆∞·ªõc khi training")
            print("="*80 + "\n")
            return True

# ============================================================================
# H√ÄM G·ªåISATTU CH∆Ø∆†NG TR√åNH CH√çNH
# ============================================================================

def validate_before_training(args, config=None):
    """
    H√†m g·ªçi t·ª´ train.py ƒë·ªÉ ki·ªÉm tra v√† hi·ªÉn th·ªã config
    
    C√°ch s·ª≠ d·ª•ng trong train.py:
    
        from config_utils import validate_before_training
        
        if __name__ == "__main__":
            # ... parse args ...
            config = get_config(args)
            
            # ‚Üê Th√™m d√≤ng n√†y
            if not validate_before_training(args, config):
                sys.exit(1)
            
            net = ViT_seg(config, ...)
            trainer_synapse(args, net, args.output_dir)
    """
    
    valid = display_training_config(args, config)
    
    if not valid:
        print("\n‚èπ  Training stopped due to configuration errors")
        return False
    
    return True

# ============================================================================
# MAIN (cho debug)
# ============================================================================

if __name__ == "__main__":
    # Test script n√†y
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--dataset', default='Synapse')
    parser.add_argument('--root_path', default='/content/project_TransUNet/data/Synapse/train_npz')
    parser.add_argument('--list_dir', default='./lists/lists_Synapse')
    parser.add_argument('--output_dir', default='./output')
    parser.add_argument('--cfg', default='configs/swin_tiny_patch4_window7_224_lite.yaml')
    parser.add_argument('--num_classes', type=int, default=9)
    parser.add_argument('--img_size', type=int, default=224)
    parser.add_argument('--batch_size', type=int, default=6)
    parser.add_argument('--n_gpu', type=int, default=1)
    parser.add_argument('--max_epochs', type=int, default=5)
    parser.add_argument('--base_lr', type=float, default=0.05)
    parser.add_argument('--num_workers', type=int, default=4)
    parser.add_argument('--eval_interval', type=int, default=1)
    parser.add_argument('--seed', type=int, default=1234)
    parser.add_argument('--deterministic', type=int, default=1)
    
    args = parser.parse_args()
    
    # Hi·ªÉn th·ªã config
    validate_before_training(args)